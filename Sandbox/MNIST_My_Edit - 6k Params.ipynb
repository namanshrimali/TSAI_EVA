{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_My_Edit - 6k Params.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","executionInfo":{"status":"ok","timestamp":1608182363365,"user_tz":-330,"elapsed":4896,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","executionInfo":{"status":"ok","timestamp":1608183867216,"user_tz":-330,"elapsed":1583,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.convLayer1 = nn.Sequential(\n","            nn.Conv2d(1, 8, 3, padding=1),            \n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Conv2d(8, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 8, 1),\n","            nn.MaxPool2d(2, 2),\n","            nn.Dropout(0.25)\n","        )\n","        self.convLayer2 = nn.Sequential(\n","            nn.Conv2d(8, 8, 3, padding=1),            \n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Conv2d(8, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 8, 1),\n","            nn.MaxPool2d(2, 2),\n","            nn.Dropout(0.25)\n","\n","        )\n","        self.convLayer3 = nn.Sequential(\n","            nn.Conv2d(8, 8, 3, padding=1),            \n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Conv2d(8, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 8, 1),\n","            nn.MaxPool2d(2, 2),\n","            nn.Dropout(0.25)\n","        )\n","        self.convLayer4 = nn.Sequential(\n","            nn.Conv2d(8, 16, 3),\n","            nn.Conv2d(16, 10, 1),\n","        )\n","\n","    def forward(self, x):\n","        x = self.convLayer1(x)\n","        x = self.convLayer2(x)\n","        x = self.convLayer3(x)\n","        x = self.convLayer4(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608183873260,"user_tz":-330,"elapsed":3345,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}},"outputId":"d1e47b73-1e3b-43da-c6cd-bc41485cbcc3"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              80\n","              ReLU-2            [-1, 8, 28, 28]               0\n","       BatchNorm2d-3            [-1, 8, 28, 28]              16\n","            Conv2d-4           [-1, 16, 28, 28]           1,168\n","              ReLU-5           [-1, 16, 28, 28]               0\n","       BatchNorm2d-6           [-1, 16, 28, 28]              32\n","            Conv2d-7            [-1, 8, 28, 28]             136\n","         MaxPool2d-8            [-1, 8, 14, 14]               0\n","           Dropout-9            [-1, 8, 14, 14]               0\n","           Conv2d-10            [-1, 8, 14, 14]             584\n","             ReLU-11            [-1, 8, 14, 14]               0\n","      BatchNorm2d-12            [-1, 8, 14, 14]              16\n","           Conv2d-13           [-1, 16, 14, 14]           1,168\n","             ReLU-14           [-1, 16, 14, 14]               0\n","      BatchNorm2d-15           [-1, 16, 14, 14]              32\n","           Conv2d-16            [-1, 8, 14, 14]             136\n","        MaxPool2d-17              [-1, 8, 7, 7]               0\n","          Dropout-18              [-1, 8, 7, 7]               0\n","           Conv2d-19              [-1, 8, 7, 7]             584\n","             ReLU-20              [-1, 8, 7, 7]               0\n","      BatchNorm2d-21              [-1, 8, 7, 7]              16\n","           Conv2d-22             [-1, 16, 7, 7]           1,168\n","             ReLU-23             [-1, 16, 7, 7]               0\n","      BatchNorm2d-24             [-1, 16, 7, 7]              32\n","           Conv2d-25              [-1, 8, 7, 7]             136\n","        MaxPool2d-26              [-1, 8, 3, 3]               0\n","          Dropout-27              [-1, 8, 3, 3]               0\n","           Conv2d-28             [-1, 16, 1, 1]           1,168\n","           Conv2d-29             [-1, 10, 1, 1]             170\n","================================================================\n","Total params: 6,642\n","Trainable params: 6,642\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.66\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.69\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","executionInfo":{"status":"ok","timestamp":1608183905230,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}}},"source":["\n","\n","torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","executionInfo":{"status":"ok","timestamp":1608183908584,"user_tz":-330,"elapsed":1422,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}}},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    correct = 0\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        \n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","    \n","    print('\\Train set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        correct, len(train_loader.dataset),\n","        100. * correct / len(train_loader.dataset)))\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608184230456,"user_tz":-330,"elapsed":319711,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}},"outputId":"30151793-abe8-4c83-8396-39bf25768db1"},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.1480870097875595 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.01it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 44940/60000 (75%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1197, Accuracy: 9637/10000 (96%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.21429359912872314 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 56549/60000 (94%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0828, Accuracy: 9737/10000 (97%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.18492256104946136 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.14it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 57346/60000 (96%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0655, Accuracy: 9790/10000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.139149472117424 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.01it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 57802/60000 (96%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0614, Accuracy: 9795/10000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.10262134671211243 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 57994/60000 (97%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0507, Accuracy: 9832/10000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.1376054584980011 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58224/60000 (97%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0466, Accuracy: 9847/10000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.14114917814731598 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58227/60000 (97%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0477, Accuracy: 9853/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.12073728442192078 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58429/60000 (97%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0425, Accuracy: 9859/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.048513978719711304 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58522/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0423, Accuracy: 9857/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.06436579674482346 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58555/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0381, Accuracy: 9871/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.18658824265003204 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58567/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0345, Accuracy: 9891/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07490949332714081 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58654/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0342, Accuracy: 9878/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05478253960609436 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58703/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0358, Accuracy: 9881/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.053908687084913254 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58789/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0325, Accuracy: 9892/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.030175426974892616 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58836/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0304, Accuracy: 9886/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.027399959042668343 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58832/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0291, Accuracy: 9903/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07418997585773468 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58828/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0342, Accuracy: 9878/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.08099599182605743 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58846/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0284, Accuracy: 9908/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04995900020003319 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58854/60000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0303, Accuracy: 9891/10000 (99%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"So5uk4EkHW6R"},"source":[""],"execution_count":null,"outputs":[]}]}