{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_My_Edit - 12k Params Success.ipynb","provenance":[{"file_id":"1mZXGZOWk6SMlVZuBcpvPmWG14l8g2sl_","timestamp":1608224674597},{"file_id":"1j66o1qtiN23NN16x2Sw1QjEqSkySh3_X","timestamp":1608186696657},{"file_id":"10rrjJDlkxo-I3hEN-dBMh8uy9cZ8P2Se","timestamp":1608184350726}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT"},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.convLayer1 = nn.Sequential(\n","            nn.Conv2d(1, 16, 3), #26\n","            nn.ReLU(),      \n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 20, 3), #24\n","            nn.ReLU(),\n","            nn.BatchNorm2d(20),\n","            nn.Conv2d(20, 10, 1), \n","            nn.MaxPool2d(2, 2), #12\n","            nn.Dropout(0.3)\n","        )\n","        self.convLayer2 = nn.Sequential(\n","            nn.Conv2d(10, 16, 3), #10 \n","            nn.ReLU(),          \n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16, 16, 3), #8\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.MaxPool2d(2, 2), #4\n","            nn.Dropout(0.3)\n","\n","        )\n","       \n","        self.convLayer4 = nn.Sequential(\n","            nn.Conv2d(16, 32, 3), #2\n","            nn.Conv2d(32, 10, 1),\n","\n","        )\n","\n","    def forward(self, x):\n","        x = self.convLayer1(x)\n","        x = self.convLayer2(x)\n","        x = self.convLayer4(x)\n","        x = F.avg_pool2d(x, 2)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608223558794,"user_tz":-330,"elapsed":4126,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}},"outputId":"9a543527-3c92-49c7-c636-073068df11f0"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 26, 26]             160\n","              ReLU-2           [-1, 16, 26, 26]               0\n","       BatchNorm2d-3           [-1, 16, 26, 26]              32\n","            Conv2d-4           [-1, 20, 24, 24]           2,900\n","              ReLU-5           [-1, 20, 24, 24]               0\n","       BatchNorm2d-6           [-1, 20, 24, 24]              40\n","            Conv2d-7           [-1, 10, 24, 24]             210\n","         MaxPool2d-8           [-1, 10, 12, 12]               0\n","           Dropout-9           [-1, 10, 12, 12]               0\n","           Conv2d-10           [-1, 16, 10, 10]           1,456\n","             ReLU-11           [-1, 16, 10, 10]               0\n","      BatchNorm2d-12           [-1, 16, 10, 10]              32\n","           Conv2d-13             [-1, 16, 8, 8]           2,320\n","             ReLU-14             [-1, 16, 8, 8]               0\n","      BatchNorm2d-15             [-1, 16, 8, 8]              32\n","        MaxPool2d-16             [-1, 16, 4, 4]               0\n","          Dropout-17             [-1, 16, 4, 4]               0\n","           Conv2d-18             [-1, 32, 2, 2]           4,640\n","           Conv2d-19             [-1, 10, 2, 2]             330\n","================================================================\n","Total params: 12,152\n","Trainable params: 12,152\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.64\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 0.69\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH"},"source":["\n","\n","torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH"},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    correct = 0\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        \n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","    \n","    print('\\Train set: Accuracy: {}/{} ({:.4f}%)\\n'.format(\n","        correct, len(train_loader.dataset),\n","        100. * correct / len(train_loader.dataset)))\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608223946211,"user_tz":-330,"elapsed":353993,"user":{"displayName":"Naman Shrimali","photoUrl":"","userId":"08968415788269079614"}},"outputId":"2be5a264-0cf0-493f-f5e1-20486d7e1cea"},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    print(f'EPOCH : {epoch}')\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["EPOCH : 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.042289912700653076 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.15it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 54764/60000 (91.2733%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0508, Accuracy: 9849/10000 (98.49%)\n","\n","EPOCH : 2\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.08214279264211655 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.57it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58460/60000 (97.4333%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0366, Accuracy: 9892/10000 (98.92%)\n","\n","EPOCH : 3\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.08283144980669022 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58817/60000 (98.0283%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0331, Accuracy: 9901/10000 (99.01%)\n","\n","EPOCH : 4\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.10258739441633224 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 58884/60000 (98.1400%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0311, Accuracy: 9904/10000 (99.04%)\n","\n","EPOCH : 5\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04741745814681053 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59010/60000 (98.3500%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0270, Accuracy: 9916/10000 (99.16%)\n","\n","EPOCH : 6\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.024632787331938744 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59048/60000 (98.4133%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0258, Accuracy: 9920/10000 (99.20%)\n","\n","EPOCH : 7\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.014709734357893467 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59060/60000 (98.4333%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0241, Accuracy: 9927/10000 (99.27%)\n","\n","EPOCH : 8\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0025329752825200558 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 27.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59179/60000 (98.6317%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0245, Accuracy: 9917/10000 (99.17%)\n","\n","EPOCH : 9\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.09031356126070023 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59210/60000 (98.6833%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0232, Accuracy: 9936/10000 (99.36%)\n","\n","EPOCH : 10\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.018328996375203133 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59220/60000 (98.7000%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0221, Accuracy: 9938/10000 (99.38%)\n","\n","EPOCH : 11\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.14880214631557465 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59284/60000 (98.8067%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0213, Accuracy: 9935/10000 (99.35%)\n","\n","EPOCH : 12\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02303299307823181 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59284/60000 (98.8067%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0201, Accuracy: 9937/10000 (99.37%)\n","\n","EPOCH : 13\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.00938570685684681 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59284/60000 (98.8067%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0224, Accuracy: 9923/10000 (99.23%)\n","\n","EPOCH : 14\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.005678325425833464 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59332/60000 (98.8867%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0211, Accuracy: 9945/10000 (99.45%)\n","\n","EPOCH : 15\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03834051266312599 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59334/60000 (98.8900%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0192, Accuracy: 9941/10000 (99.41%)\n","\n","EPOCH : 16\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04425505921244621 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59348/60000 (98.9133%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0205, Accuracy: 9934/10000 (99.34%)\n","\n","EPOCH : 17\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.09310799837112427 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59340/60000 (98.9000%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0209, Accuracy: 9938/10000 (99.38%)\n","\n","EPOCH : 18\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.009465865790843964 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59330/60000 (98.8833%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0200, Accuracy: 9940/10000 (99.40%)\n","\n","EPOCH : 19\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0015575833385810256 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["\\Train set: Accuracy: 59406/60000 (99.0100%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0193, Accuracy: 9931/10000 (99.31%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"So5uk4EkHW6R"},"source":[""],"execution_count":null,"outputs":[]}]}